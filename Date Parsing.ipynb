{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Exploratory Data Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardMWarburton/ExploringCUAD/blob/Dev/Date%20Parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlHNM0ylUtXc"
      },
      "source": [
        "# Individual Clause Investigation (Agreement Date)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ4UlOkTUtXj"
      },
      "source": [
        "## The Data\n",
        "\n",
        "CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review\n",
        "\n",
        "https://arxiv.org/abs/2103.06268\n",
        "\n",
        "This code is an adaptation of the scrape.py file avaliable on the github repository for CUAD.  It has been adapted to run in Jypter notebooks and allow us to step throght the coding line by line.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maa-snhRqRjR"
      },
      "source": [
        "## 1: Import Packages & Define Useful Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s41Gdd-7UtXh",
        "outputId": "c086ed67-5ec7-4b39-a416-0747d73b285b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import json\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from random import sample, choice\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import DBSCAN, KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from pprint import pprint\n",
        "\n",
        "!pip install dateparser\n",
        "import dateparser"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser) (2018.9)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAHzdcCrUtXl"
      },
      "source": [
        "def extract_zip(pth,data_pth = None):\n",
        "    \"\"\"Function to extract contents of a zip file to a specified location (wd if data_pth not passed)\"\"\"\n",
        "    with ZipFile(pth, 'r') as zipObj:\n",
        "       # Extract all the contents of zip file in different directory\n",
        "       zipObj.extractall(data_pth)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5RS1m1RUtXk"
      },
      "source": [
        "## 2: Download repository and extract data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWljb-PkUtXm"
      },
      "source": [
        "#Download CUAD git repository\n",
        "if not os.path.exists('main.zip'):\n",
        "  !wget --no-check-certificate https://github.com/TheAtticusProject/cuad/archive/refs/heads/main.zip\n",
        "  !unzip -q main.zip\n",
        "\n",
        "#If it has not already been extracted, extract the contents of data.zip\n",
        "if not os.path.exists('cuad-main/data'):\n",
        "  os.makedirs('cuad-main/data')\n",
        "\n",
        "if not os.path.exists('cuad-main/data/CUADv1.json'):\n",
        "  extract_zip('cuad-main/data.zip','cuad-main/data/')\n",
        "\n",
        "#Download a manualy curated set of labels for the full CUAD data. \n",
        "if not os.path.exists('labels3.txt'):\n",
        "  !wget https://raw.githubusercontent.com/RichardMWarburton/ExploringCUAD/main/labels3.txt"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j6zwYHHUtXp"
      },
      "source": [
        "#Load CUADv1 JSON to data\n",
        "with open('cuad-main/data/CUADv1.json','r') as infile:\n",
        "    for line in infile:\n",
        "        contract_data = json.loads(line)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_1H8XPNxNTG"
      },
      "source": [
        "### 2.1: Read in Label Data & Generate Look Up Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHqEpKU5xNjB"
      },
      "source": [
        "#Initate storage for labels look up (LU)\n",
        "labels_LU = {}\n",
        "\n",
        "#Read in labels data\n",
        "with open('labels3.txt','r',encoding ='UTF-8') as infile:\n",
        "  for line in infile:\n",
        "    #Remove trailing special characters and split on tab\n",
        "    data = line.strip().split(sep='\\t')\n",
        "    #Add name and label to labels_LU dictionary\n",
        "    labels_LU[data[0]] = data[1]"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjA7wac3yse"
      },
      "source": [
        "The look up returns one error, most likely due to the accented E and a disparity of encoding.  This will be forced to 'Marketing Agreement' manually for now (EITHER SORT OR PROVIDE EXAMPLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igP7vzKnqac7"
      },
      "source": [
        "### 2.2: Extract Raw Contract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgadIkwcqemy"
      },
      "source": [
        "#ser reg ex expression for characters to remove from contract contest\n",
        "spec_chars = '\\\\n|\\\\t|\\\\t'\n",
        "\n",
        "#Set number of contracts in data\n",
        "num_contracts = len(contract_data['data'])\n",
        "\n",
        "#Initate dictionary to store raw contract data\n",
        "raw_contracts = defaultdict(list)\n",
        "\n",
        "#for each contract\n",
        "for i in range(num_contracts):\n",
        "  #Append the title, contract text and character length of text to the raw_contracts dictionary\n",
        "  raw_contracts['contract title'].append(contract_data['data'][i]['title'])\n",
        "  raw_contracts['label'].append(labels_LU[contract_data['data'][i]['title']] if contract_data['data'][i]['title'] in labels_LU else 'marketing agreement' ) #<- manual error trap applied here (see below)\n",
        "  \n",
        "  #Parse raw text and process to remove breaks\n",
        "  raw_text = contract_data['data'][i]['paragraphs'][0]['context']\n",
        "  clean_text = re.sub(spec_chars,'',raw_text)\n",
        "\n",
        "  #Split clean text in to sentances and tokens\n",
        "  sentance_text = clean_text.split(sep = '. ')\n",
        "  token_text = clean_text.split(sep = ' ')\n",
        "\n",
        "  #Append text to the respective key in the raw_contracts dictionary\n",
        "  raw_contracts['raw text'].append(raw_text)\n",
        "  raw_contracts['clean text'].append(clean_text)\n",
        "  raw_contracts['sentance text'].append(sentance_text)\n",
        "  raw_contracts['token text'].append(token_text)\n",
        "  \n",
        "  #Add character, sentance and token counts to raw_contracts dictionary\n",
        "  raw_contracts['character count'].append(len(raw_text))\n",
        "  raw_contracts['sentance count'].append(len(sentance_text))\n",
        "  raw_contracts['token count'].append(len(token_text))\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n876lWEZsh7o"
      },
      "source": [
        "### 2.3: Extract Clause Specific Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg1TjBOurSrD"
      },
      "source": [
        "#Define the number of clauses\n",
        "num_clauses = 41\n",
        "\n",
        "#initate dictioanry to store caluse data\n",
        "clause_data = defaultdict(list)\n",
        "\n",
        "#For each contract\n",
        "for i in range(num_contracts):\n",
        "  #for each clause\n",
        "  for j in range(num_clauses):\n",
        "    #for each found clause annotation\n",
        "    for k in range(len(contract_data['data'][i]['paragraphs'][0]['qas'][j]['answers'])): \n",
        "      #Add the contract title\n",
        "      clause_data['contract title'].append(contract_data['data'][i]['title'])\n",
        "      clause_data['label'].append(labels_LU[contract_data['data'][i]['title']] if contract_data['data'][i]['title'] in labels_LU else 'marketing agreement' )  #<- manual error trap applied here\n",
        "      clause_data['clause'].append(contract_data['data'][i]['paragraphs'][0]['qas'][j]['id'].split(sep='__')[1])\n",
        "      clause_data['annotation'].append(contract_data['data'][i]['paragraphs'][0]['qas'][j]['answers'][k]['text'])\n",
        "      clause_data['annotation start'].append(contract_data['data'][i]['paragraphs'][0]['qas'][j]['answers'][k]['answer_start'])\n",
        "      clause_data['annotation length'].append(len(contract_data['data'][i]['paragraphs'][0]['qas'][j]['answers'][k]['text']))\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2qHd0moLY4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114d3868-b155-4514-9851-5b61d26e53c7"
      },
      "source": [
        "np.unique(clause_data['clause'])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Affiliate License-Licensee', 'Affiliate License-Licensor',\n",
              "       'Agreement Date', 'Anti-Assignment', 'Audit Rights',\n",
              "       'Cap On Liability', 'Change Of Control',\n",
              "       'Competitive Restriction Exception', 'Covenant Not To Sue',\n",
              "       'Document Name', 'Effective Date', 'Exclusivity',\n",
              "       'Expiration Date', 'Governing Law', 'Insurance',\n",
              "       'Ip Ownership Assignment', 'Irrevocable Or Perpetual License',\n",
              "       'Joint Ip Ownership', 'License Grant', 'Liquidated Damages',\n",
              "       'Minimum Commitment', 'Most Favored Nation',\n",
              "       'No-Solicit Of Customers', 'No-Solicit Of Employees',\n",
              "       'Non-Compete', 'Non-Disparagement', 'Non-Transferable License',\n",
              "       'Notice Period To Terminate Renewal', 'Parties',\n",
              "       'Post-Termination Services', 'Price Restrictions', 'Renewal Term',\n",
              "       'Revenue/Profit Sharing', 'Rofr/Rofo/Rofn', 'Source Code Escrow',\n",
              "       'Termination For Convenience', 'Third Party Beneficiary',\n",
              "       'Uncapped Liability', 'Unlimited/All-You-Can-Eat-License',\n",
              "       'Volume Restriction', 'Warranty Duration'], dtype='<U34')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ojxytoG46D9"
      },
      "source": [
        "## 3: Cleaning data and extracting a single clause"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXET1UnSbTpM"
      },
      "source": [
        "#Initate dataframe of all clause data\n",
        "clause_df = pd.DataFrame(clause_data)\n",
        "\n",
        "#Convert to lower case\n",
        "clause_df['annotation'] = clause_df['annotation'].apply(lambda x: x.lower())\n",
        "\n",
        "#Remove any formating characters or multiple spaces and replace with a single space\n",
        "clause_df['annotation'] = clause_df['annotation'].apply(lambda x: re.sub('\\\\t|\\\\r|\\\\n|[^\\S]{2,}',' ',x))\n",
        "\n",
        "#Remove punctuation from the string\n",
        "clause_df['annotation'] = clause_df['annotation'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3xFTGsWJ0fH",
        "outputId": "158148f0-52f0-4ef3-b3ac-637170400ddd"
      },
      "source": [
        "#Define clause of interest\n",
        "clause_of_interest = 'Agreement Date'\n",
        "\n",
        "#Limit df to clause of interest and extract annotations of itnerest\n",
        "of_interest_data = clause_df[clause_df['clause'] == clause_of_interest]\n",
        "annotations_of_interest = of_interest_data['annotation'].values\n",
        "\n",
        "#Identify where there are multiple annotations per contract\n",
        "titles,counts = np.unique(of_interest_data['contract title'],return_counts =True)\n",
        "dups = titles[counts >= 2]\n",
        "\n",
        "#Output Analysis\n",
        "print('There are {} contracts with \\'{}\\' annotations'.format(*(titles.shape[0],clause_of_interest)))\n",
        "print('There are {} contracts with more than one annotation'.format(dups.shape[0]))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 470 contracts with 'Agreement Date' annotations\n",
            "There are 6 contracts with more than one annotation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CRZkfULhlnS"
      },
      "source": [
        "From the above we can see that: \n",
        "\n",
        "1.   Contracts may have multiple annotations for the same clause\n",
        "2.   Not all contracts have an annotation of interest\n",
        "\n",
        "Provisionally, we will look to concatinate all such annotations for a contract in to one string.  This will then represent all the salient points for the contract and clause in question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwhtFSughlvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774eab36-0b53-46c1-e1cb-bb052c4524d9"
      },
      "source": [
        "#output duplicate annotations anc contract titles\n",
        "dup_df = of_interest_data[of_interest_data['contract title'].isin(dups)][['contract title','annotation']]\n",
        "\n",
        "#print sample of duplicate annotations\n",
        "for i in dup_df.index[:8]:\n",
        "  print(dup_df.loc[i,'contract title'])\n",
        "  print(repr(dup_df.loc[i,'annotation']))\n",
        "  #print(dup_df.loc[i,'annotation'].split(sep=' '))\n",
        "  print('\\n')"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OASYSMOBILE,INC_07_05_2001-EX-10.17-OUTSOURCING AGREEMENT\n",
            "'31 day of july 2000'\n",
            "\n",
            "\n",
            "OASYSMOBILE,INC_07_05_2001-EX-10.17-OUTSOURCING AGREEMENT\n",
            "'july  2000'\n",
            "\n",
            "\n",
            "GULFSOUTHMEDICALSUPPLYINC_12_24_1997-EX-4-AFFILIATE AGREEMENT\n",
            "'agreed to and accepted as of december 14 1997'\n",
            "\n",
            "\n",
            "GULFSOUTHMEDICALSUPPLYINC_12_24_1997-EX-4-AFFILIATE AGREEMENT\n",
            "'this affiliate agreement is executed as of the 14th day of december 1997'\n",
            "\n",
            "\n",
            "Apollo Endosurgery - Manufacturing and Supply Agreement\n",
            "'effective date shall mean december 5 2014'\n",
            "\n",
            "\n",
            "Apollo Endosurgery - Manufacturing and Supply Agreement\n",
            "'this agreement as of the effective date'\n",
            "\n",
            "\n",
            "BEYONDCOMCORP_08_03_2000-EX-10.2-CO-HOSTING AGREEMENT\n",
            "'92198'\n",
            "\n",
            "\n",
            "BEYONDCOMCORP_08_03_2000-EX-10.2-CO-HOSTING AGREEMENT\n",
            "'september 21 1998'\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDOLIqlkFMfJ"
      },
      "source": [
        "**THE ABOVE COULD BE DISPLAYED BETTER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiO83dK-iZvG"
      },
      "source": [
        "#Initate memory for annotations within contracts\n",
        "combined_annotations_list = defaultdict(list)\n",
        "combined_annotations_string = {}\n",
        "\n",
        "#For each annotation of interest found in the contract, \n",
        "#append annotation to a default dict list with contract as key\n",
        "for i in of_interest_data.index:\n",
        "  name = of_interest_data.loc[i,['contract title']].values[0]\n",
        "  annotation = of_interest_data.loc[i,['annotation']].values[0]\n",
        "  combined_annotations_list[name].append(annotation)\n",
        "\n",
        "#Produce a singel string of all annotations found in specific contracts\n",
        "for key in combined_annotations_list.keys():\n",
        "  combined_annotations_string[key] = ' '.join(combined_annotations_list[key])"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyJbopX_jFY5"
      },
      "source": [
        "#Build array of contract names and concatenated annotations\n",
        "contracts = np.array(list(combined_annotations_string.keys()))\n",
        "combined_annotations = np.array(list(combined_annotations_string.values()))"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY-ntF9--xyd",
        "outputId": "e0b7d4bc-dbff-40e0-f1a6-5154fcfbbfe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "combined_annotations.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhVHMAUR-x1Y"
      },
      "source": [
        "txt = combined_annotations[0]"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYMzjFW8-x4N"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfBM5w4k-yk3"
      },
      "source": [
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrYcnjSA-4yF",
        "outputId": "df6044ce-dd09-4680-b99d-caeb4b354aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(repr(txt))\n",
        "print([(X.text, X.label_) for X in doc.ents])"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(\"'7th day of september 1999'\", 'DATE')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ8JIWvs_GOk"
      },
      "source": [
        "def append_type_match(x, value_list,matches=[]):\n",
        "  if x.label_ in matches:\n",
        "    value_list.append(x)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuhyyGfLA_yE"
      },
      "source": [
        "def ordinalize_num(txt):\n",
        "  for token in txt.split(sep=' '):\n",
        "    try:\n",
        "      if int(token) <= 31:\n",
        "        ord_val = num2words(token, lang=\"en\", to=\"ordinal_num\")\n",
        "        txt = txt.replace(token,ord_val)\n",
        "    except:\n",
        "      continue\n",
        "  return txt"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEqdjUUo_4LU"
      },
      "source": [
        "date_feature_list = []\n",
        "not_mapped = []\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "for annotation in combined_annotations:\n",
        "\n",
        "\n",
        "  annotation_list = []  \n",
        "  \n",
        "  annotation = annotation.replace('t h','th')\n",
        "  annotation = annotation.replace('s t','st')\n",
        "  annotation = annotation.replace('day','')\n",
        "  annotation = ordinalize_num(annotation)\n",
        "\n",
        "  doc = nlp(repr(annotation))\n",
        "\n",
        "  for X in doc.ents:\n",
        "    if X.label_ in ['DATE']:\n",
        "\n",
        "      annotation_list.append(X.text)\n",
        "    else:\n",
        "      not_mapped.append(annotation)\n",
        "  date_feature_list.append(' '.join(annotation_list))\n"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EK2DoRyARN0",
        "outputId": "c93214bd-0b5e-496e-f26b-97f71b7a0f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt_list = np.array(date_feature_list)\n",
        "\n",
        "pass_vals = list(map(dateparser.parse,dt_list))\n",
        "matched = sum(list(map(lambda x: 1 if x == None else 0,pass_vals)))\n",
        "print('Pass 1: {} of {} not matched ({:.2%})'.format(*(matched,len(pass_vals),matched/len(pass_vals))))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass 1: 54 of 470 not matched (11.49%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oQF6MHJ_Vh5",
        "outputId": "ce4d24c8-a252-4c15-88ef-3481079c848f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dt_list = (list(map(lambda x: x.replace('day',''),dt_list)))\n",
        "\n",
        "pass_vals = list(map(dateparser.parse,dt_list))\n",
        "matched = sum(list(map(lambda x: 1 if x == None else 0,pass_vals)))\n",
        "print('Pass 2: {} of {} not matched ({:.2%})'.format(*(matched,len(pass_vals),matched/len(pass_vals))))"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass 2: 54 of 470 not matched (11.49%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BtLP4yRAxmV",
        "outputId": "84365fd9-d723-4342-a363-bcd353409715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(len(pass_vals)):\n",
        "  if pass_vals[i] == None:\n",
        "    print(dt_list[i])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this 2nd january 2020'\n",
            "12232019\n",
            "'1st october 201st9'\n",
            "'14th  of september 200'\n",
            "september 200'\n",
            "19th jan 19th98\n",
            "29318\n",
            "'31st  of july 2000 july  2000'\n",
            "\n",
            "october 11996'\n",
            "\n",
            "030105\n",
            "december 14th 1997 december 1997'\n",
            "32108\n",
            "4282017\n",
            "\n",
            "11410\n",
            "august 9th 19th9th9th'\n",
            "032406\n",
            "\n",
            "1272020\n",
            "1892008\n",
            "32006\n",
            "33116\n",
            "\n",
            "november 19th 19th99'\n",
            "482020\n",
            "71811\n",
            "february 20th 20th20th'\n",
            "51712\n",
            "this 15th july 1998'\n",
            "april 2nd 2nd02nd0'\n",
            "130705\n",
            "october 1st 1st999\n",
            "'january 20th 20th14'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "31418\n",
            "'1st august 201st9'\n",
            "\n",
            "march 20th 20th20th'\n",
            "may 8th 2014 may 2014'\n",
            "march 121999'\n",
            "march 20th 20th20th'\n",
            "\n",
            "11402\n",
            "050598\n",
            "9282004\n",
            "92904\n",
            "'2nd april 2nd02nd0'\n",
            "9242018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVxNSR_dA8x8",
        "outputId": "87ff33e5-186a-4a11-b7da-43d524906c00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install num2words\n",
        "from num2words import num2words"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting num2words\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 101 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "Installing collected packages: num2words\n",
            "Successfully installed num2words-0.5.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855Zxg1Ixw93",
        "outputId": "848b506b-adb7-43a4-89dd-ff11d9ff6429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30th of june 2016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aPAM6uZGWIA",
        "outputId": "8991744a-33fa-4485-e8c4-8967fed1715e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        ""
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'30th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V76HRNa8GZEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}